{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXY2LdbLGIoC"
      },
      "source": [
        "# Семинар 9 - Методы построения оптического потока по последовательности изображений\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ2-QWn3GIoE"
      },
      "source": [
        "Источник - https://habr.com/ru/post/201406/\n",
        "\n",
        "$\\textbf{Task statement}$: Оптический поток (ОП) – изображение видимого движения, представляющее собой сдвиг каждой точки (пикселя) между двумя изображениями.\n",
        "\n",
        "По сути, он представляет собой поле скоростей. Суть ОП в том, что для каждой точки изображения $I_{t_0} (\\vec{r})$ находится такой вектор сдвига $\\delta \\vec{r}$, чтобы было соответсвие между исходной точкой и точкой на следущем фрейме $I_{t_1} (\\vec{r} + \\delta \\vec{r})$. В качестве метрики соответвия берут близость интенсивности пикселей, беря во внимание маленькую разницу по времени между кадрами: $\\delta{t} = t_{1} - t_{0}$. В более точных методах точку можно привязывать к объекту на основе, например, выделения ключевых точек, а также считать градиенты вокруг точки, лапласианы и проч.\n",
        "\n",
        "$\\textbf{For what}$: Определение собственной скорости, Определение локализации, Улучшение методов трекинга объектов, сегментации, Детектирование событий, Сжатие видеопотока и проч.\n",
        "\n",
        "![](data/tennis.png)\n",
        "\n",
        "Разделяют 2 вида оптического потока - плотный (dense) [Farneback method, neural nets], работающий с целым изображением, и выборочный (sparse) [Lucas-Kanade method], работающий с ключевыми точками"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "3MQuKf5KGIoG"
      },
      "outputs": [],
      "source": [
        "# !wget https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O data/slow_traffic_small.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GtJQ-xlHGIoH"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CavJ-_22GIoH"
      },
      "source": [
        "## Lucas-Kanade (sparse)\n",
        "\n",
        "Пусть $I_{1} = I(x, y, t_{1})$ интенсивность в некоторой точке (x, y) на первом изображении (т. е. в момент времени t). На втором изображении эта точка сдвинулась на (dx, dy), при этом прошло время dt, тогда $I_{2} = I(x + dx, y + dx, t_{1} + dt) \\approx I_{1} + I_{x}dx + I_{y}dy +  I_{t}dt$. Из постановки задачи следует, что интенсивность пикселя не изменилась, тогда $I_{1} = I_{2}$. Далее определяем $dx, dy$.\n",
        "\n",
        "Самое простое решение проблемы – алгоритм Лукаса-Канаде. У нас же на изображении объекты размером больше 1 пикселя, значит, скорее всего, в окрестности текущей точки у других точек будут примерно такие же сдвиги. Поэтому мы возьмем окно вокруг этой точки и минимизируем (по МНК) в нем суммарную погрешность с весовыми коэффициентами, распределенными по Гауссу, то есть так, чтобы наибольший вес имели пиксели, ближе всего находящиеся к исследуемому.\n",
        "\n",
        "**Полезные материалы:**\n",
        "- цикл видео-лекций от First Principles of Computer Vision, посвященный Optical Flow и алгоритму Lucas-Kanade: https://youtube.com/playlist?list=PL2zRqk16wsdoYzrWStffqBAoUY8XdvatV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj-EQCs6GIoI"
      },
      "source": [
        "### Вопрос 1\n",
        "\n",
        "В `cv2.calcOpticalFlowPyrLK` есть параметр, отвечающий за ImagePiramyd. Зачем нужна пирамида изображений в случае вычисления оптического потока?\n",
        "\n",
        "**Ответ:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MjVCGGpGIoI"
      },
      "source": [
        "### Задание 1\n",
        "\n",
        "Напишите реализацию Лукаса-Канаде c помощью numpy и cv2. Сравните с реализацией `cv2.calcOpticalFlowPyrLK`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5eoblCmsGIoI"
      },
      "outputs": [],
      "source": [
        "def get_derivative_x(\n",
        "    prevImg,\n",
        "    keypoint,\n",
        "    winSize,\n",
        ") -> np.array:\n",
        "    # Your code here\n",
        "    kernel_x = np.array([[-1, 1], [-1, 1]])\n",
        "    kernel_y = np.array([[-1, -1], [1, 1]])\n",
        "    kernel_t = np.array([[1, 1], [1, 1]])\n",
        "\n",
        "    dx = cv2.filter2D(img1, -1, kernel_x)\n",
        "    dy = cv2.filter2D(img1, -1, kernel_y)\n",
        "    dt = cv2.filter2D(img2, -1, kernel_t) + cv2.filter2D(img1, -1, -kernel_t)\n",
        "\n",
        "    return dx, dy, dt\n",
        "\n",
        "\n",
        "# arguments like in cv2 lib\n",
        "def my_calcOpticalFlowPyrLK(\n",
        "    prevImg,\n",
        "    nextImg,\n",
        "    prevPts,\n",
        "    nextPts, #None is our case\n",
        "    winSize,\n",
        "    #maxLevel, if you want to be an expert in CV,\n",
        "    #uncomment it and apply in LK method :)\n",
        ") -> np.array:\n",
        "\n",
        "    '''\n",
        "    You should return output vector of 2D points\n",
        "    (with single-precision floating-point coordinates)\n",
        "    containing the calculated new positions of input features in the second image\n",
        "    '''\n",
        "    nextPts = []\n",
        "    dx, dy, dt = get_derivatives(prevImg, nextImg)\n",
        "    w = (winSize[0]//2, winSize[1]//2)\n",
        "    for keypoint in prevPts:\n",
        "        # find a matrix and solve linear equation system\n",
        "        # Your code here\n",
        "        keypoint = keypoint.ravel()\n",
        "        i, j = [int(_) for _ in keypoint[::-1]]\n",
        "\n",
        "        Ix = dx[i-w[0]:i+w[0]+1, j-w[1]:j+w[1]+1].flatten()\n",
        "        Iy = dy[i-w[0]:i+w[0]+1, j-w[1]:j+w[1]+1].flatten()\n",
        "        It = dt[i-w[0]:i+w[0]+1, j-w[1]:j+w[1]+1].flatten()\n",
        "\n",
        "        b = It.reshape(-1, 1)\n",
        "        A = np.vstack((Ix, Iy)).T\n",
        "\n",
        "        output = np.linalg.lstsq(A, b, rcond=1e-3)[0].ravel()\n",
        "        # find result coordinates\n",
        "        if output.all():\n",
        "            nextPts.append([keypoint + output])\n",
        "\n",
        "    return np.expand_dims(np.stack(nextPts), axis=1) if len(nextPts) else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlc8bLsDGIoI"
      },
      "source": [
        "### Релизация OpenCV - cv2.calcOpticalFlowPyrLK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFMTJsFGGIoI",
        "outputId": "f4cf9698-e658-4a90-825d-b82f062a92b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 913/914 [00:14<00:00, 62.18it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No frames grabbed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# video_path = 'data/slow_traffic_small.mp4'\n",
        "video_path = '/content/slow_traffic_small.mp4'\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "out = cv2.VideoWriter('output_LK.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "# params for ShiTomasi corner detection\n",
        "feature_params = dict(\n",
        "    maxCorners = 100,\n",
        "    qualityLevel = 0.3,\n",
        "    minDistance = 7,\n",
        "    blockSize = 7,\n",
        ")\n",
        "\n",
        "# Parameters for lucas kanade optical flow\n",
        "lk_params = dict(\n",
        "    #window size\n",
        "    winSize  = (15, 15),\n",
        "    #image piramid\n",
        "    maxLevel = 2,\n",
        "    #after the specified maximum number of iterations criteria.maxCount\n",
        "    #or when the search window moves by less than criteria.epsilon.\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
        ")\n",
        "# Create some random colors\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "# Take first frame and find corners in it\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
        "# Create a mask image for drawing purposes\n",
        "mask = np.zeros_like(old_frame)\n",
        "for i in tqdm(range(length)):\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        print('No frames grabbed!')\n",
        "        break\n",
        "\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # calculate optical flow\n",
        "    # see params here https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323\n",
        "    p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
        "        prevImg=old_gray,\n",
        "        nextImg=frame_gray,\n",
        "        prevPts=p0,\n",
        "        nextPts=None,\n",
        "        **lk_params,\n",
        "    )\n",
        "\n",
        "    # Select good points where status is equal 1\n",
        "    if p1 is not None:\n",
        "        good_new = p1[st==1]\n",
        "        good_old = p0[st==1]\n",
        "\n",
        "    # draw the tracks\n",
        "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "        a, b = new.ravel()\n",
        "        c, d = old.ravel()\n",
        "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
        "        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "    # Now update the previous frame and previous points\n",
        "    old_gray = frame_gray.copy()\n",
        "    p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "    out.write(img)\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/output_LK.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "TKGenSQyGIoK",
        "outputId": "b4e93c20-3d19-4188-e460-46cf27a82c77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"output_LK.mp4\" controls  >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "IPython.display.Video('output_LK.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag6SSRf4GIoK"
      },
      "source": [
        "### Вопрос 2\n",
        "\n",
        "Какие проблемы в текущей реализации вы увидели при просмотре результирующего видео? Как их можно устранить?\n",
        "\n",
        "**Ответ:** фиксация ключевых точек происходит только на первом кадре видео, из-за чего строится неполный поток."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxyEoVJFGIoK"
      },
      "source": [
        "### Задание 2\n",
        "\n",
        "Напишите код, устраняющий одну из проблем, покажите результат до/после."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def track_kp(img):\n",
        "    return cv2.goodFeaturesToTrack(img, mask = None, **feature_params)\n",
        "\n",
        "# video_path = 'data/slow_traffic_small.mp4'\n",
        "video_path = '/content/slow_traffic_small.mp4'\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "out = cv2.VideoWriter('output_LK_fix.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "# params for ShiTomasi corner detection\n",
        "feature_params = dict(\n",
        "    maxCorners = 100,\n",
        "    qualityLevel = 0.3,\n",
        "    minDistance = 7,\n",
        "    blockSize = 7,\n",
        ")\n",
        "\n",
        "# Parameters for lucas kanade optical flow\n",
        "lk_params = dict(\n",
        "    #window size\n",
        "    winSize  = (15, 15),\n",
        "    #image piramid\n",
        "    maxLevel = 2,\n",
        "    #after the specified maximum number of iterations criteria.maxCount\n",
        "    #or when the search window moves by less than criteria.epsilon.\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
        ")\n",
        "# Create some random colors\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "# Take first frame and find corners in it\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
        "# Create a mask image for drawing purposes\n",
        "mask = np.zeros_like(old_frame)\n",
        "for i in tqdm(range(length)):\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        print('No frames grabbed!')\n",
        "        break\n",
        "\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # calculate optical flow\n",
        "    # see params here https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323\n",
        "    p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
        "        prevImg=old_gray,\n",
        "        nextImg=frame_gray,\n",
        "        prevPts=p0,\n",
        "        nextPts=None,\n",
        "        **lk_params,\n",
        "    )\n",
        "\n",
        "    # Select good points where status is equal 1\n",
        "    if p1 is not None:\n",
        "        good_new = p1[st==1]\n",
        "        good_old = p0[st==1]\n",
        "\n",
        "    # draw the tracks\n",
        "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "        a, b = new.ravel()\n",
        "        c, d = old.ravel()\n",
        "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
        "        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "    # Now update the previous frame and previous points\n",
        "    old_gray = frame_gray.copy()\n",
        "    p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "    if np.array([(p > old_frame.shape).all() for p in p0.ravel()]).any():\n",
        "        # если поток одной из ключевых точек находится за пределами фрейма, то\n",
        "        # происходит обновление точек и запуск потока\n",
        "        p0 = track_kp(old_gray)\n",
        "\n",
        "    out.write(img)\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hViR_rb1ItaJ",
        "outputId": "2fc85271-86fc-404e-94a3-2b8659040cdf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 913/914 [00:04<00:00, 182.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No frames grabbed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.Video('output_LK_fix.mp4')"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/output_LK_fix.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "jzO_WO95I1R7",
        "outputId": "8a59784d-5695-4a1e-d3da-96c0c0cb2c4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"output_LK_fix.mp4\" controls  >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "То, что было до фикса `/data/output_LK.mp4`, а вот что стало после $-$ `/data/output_LK_fix.mp4`"
      ],
      "metadata": {
        "id": "5dN-BzneKlXp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWdLwbCzGIoK"
      },
      "source": [
        "## Farneback (dense)\n",
        "\n",
        "Метод Farneback носит несколько более глобальный характер, чем метод Лукаса-Канаде. Он опирается на предположение о том, что на всем изображении оптический поток будет достаточно гладким."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfS3N1oYGIoL",
        "outputId": "fbac0d82-9f7c-4cad-995a-390930832f7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 913/914 [01:29<00:00, 10.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No frames grabbed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "out = cv2.VideoWriter('output_Farneback.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "ret, frame1 = cap.read()\n",
        "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
        "hsv = np.zeros_like(frame1)\n",
        "hsv[..., 1] = 255\n",
        "\n",
        "for i in tqdm(range(length)):\n",
        "\n",
        "    ret, frame2 = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        print('No frames grabbed!')\n",
        "        break\n",
        "\n",
        "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    #see arguments here https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af\n",
        "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "    hsv[..., 0] = ang*180/np.pi/2\n",
        "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    prvs = next\n",
        "\n",
        "    out.write(bgr)\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLywmQD6GIoL"
      },
      "source": [
        "Посмотрим, что получилось"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/output_Farneback.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "_aZR7mEKGIoL",
        "outputId": "a2fc85af-96de-462e-99ad-5e2da0b44953"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"output_Farneback.mp4\" controls  >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "IPython.display.Video('output_Farneback.mp4')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}